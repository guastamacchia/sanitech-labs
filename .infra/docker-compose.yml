# ======================================================
# Sanitech infrastructure stack (tech components)
# ======================================================
services:

  # =========================
  # Keycloak
  # =========================
  # Identity Provider (OIDC) usato dai microservizi.
  keycloak:
    build:
      context: ./keycloak
    container_name: sanitech-keycloak
    environment:
      # =========================
      # Bootstrap admin user
      # =========================
      KC_BOOTSTRAP_ADMIN_USERNAME: ${KC_BOOTSTRAP_ADMIN_USERNAME}
      KC_BOOTSTRAP_ADMIN_PASSWORD: ${KC_BOOTSTRAP_ADMIN_PASSWORD}
      # =========================
      # Health endpoint
      # =========================
      KC_HEALTH_ENABLED: ${KC_HEALTH_ENABLED}
      # Avvio in modalità dev con DB embedded.
    ports:
      # Espone la console di amministrazione
      - "8081:8080"
    healthcheck:
      # Verifica che Keycloak sia in ascolto sulla porta HTTP
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8080'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 40s
    restart: unless-stopped

  # =========================
  # Kafka (KRaft)
  # =========================
  # Message broker usato per comunicazioni asincrone/event-driven.
  # Configurato in modalità KRaft (senza Zookeeper).
  #
  # Listener:
  # - INTERNAL: per i container Docker (kafka:9092)
  # - EXTERNAL: per accesso dall'host (${KAFKA_ADVERTISED_HOST}:29092)
  kafka:
    image: confluentinc/cp-kafka:7.7.1
    container_name: sanitech-kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      # =========================
      # KRaft core
      # =========================
      # Single node: broker + controller nello stesso processo.
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      # =========================
      # Controller listener (KRaft)
      # =========================
      # Porta dedicata al ruolo di controller in modalità KRaft.
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      # Listener per il controller.
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # =========================
      # Listeners (INTERNAL/EXTERNAL/CONTROLLER)
      # =========================
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:29092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://${KAFKA_ADVERTISED_HOST}:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      # =========================
      # KRaft storage
      # =========================
      CLUSTER_ID: ${CLUSTER_ID}
      # =========================
      # Single-node settings
      # =========================
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server kafka:9092 >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 30
      start_period: 60s
    volumes:
      # Persistenza dei log e dei dati di Kafka (KRaft)
      - kafka-data:/var/lib/kafka/data
    restart: unless-stopped

  # =========================
  # Mailpit (SMTP + Web UI)
  # =========================
  mailhog:
    image: axllent/mailpit:latest
    container_name: sanitech-mailhog
    environment:
      MP_UI_AUTH: ${MAILPIT_UI_AUTH}
    ports:
      - "1025:1025"
      - "8025:8025"
    healthcheck:
      test: ["CMD-SHELL", "wget -q --server-response --spider http://127.0.0.1:8025/ 2>&1 | grep -qE 'HTTP/1\\.[01] (200|401)'"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 10s
    restart: unless-stopped

  # =========================
  # MinIO (S3-compatible)
  # =========================
  minio:
    image: minio/minio:latest
    container_name: sanitech-minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio-data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/9000'"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 15s
    restart: unless-stopped

  # Inizializza bucket "sanitech-docs"
  minio-mc:
    image: minio/mc:latest
    container_name: sanitech-minio-mc
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      S3_BUCKET: ${S3_BUCKET}
    entrypoint: >
      /bin/sh -c "
      mc alias set local http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD} &&
      mc mb --ignore-existing local/${S3_BUCKET} &&
      mc anonymous set none local/${S3_BUCKET} &&
      echo 'Bucket ${S3_BUCKET} pronto.';"
    restart: on-failure

    # =========================
    # LiveKit (WebRTC SFU per tele-visite.)
    # =========================
  livekit:
    build:
      context: ./livekit
    image: sanitech-livekit-server:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-livekit
    command: ["--config", "/etc/livekit/livekit.yaml"]
    # Usa network_mode: host per risolvere problemi WebRTC in ambiente locale
    # Le porte 7880, 7881, 7882 saranno esposte direttamente sull'host
    network_mode: host
    restart: unless-stopped

  # =========================
  # Prometheus
  # =========================
  # Raccolta delle metriche esposte dai servizi (Spring Actuator /prometheus).
  prometheus:
    build:
      context: ./prometheus
    container_name: sanitech-prometheus
    command:
      # File di configurazione statico di Prometheus.
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --web.console.libraries=/usr/share/prometheus/console_libraries
      - --web.console.templates=/usr/share/prometheus/consoles
    ports:
      # Espone l'interfaccia web di Prometheus sull'host.
      - "9090:9090"
    volumes:
      # Persistenza delle serie temporali.
      - prometheus-data:/prometheus
    healthcheck:
      # Verifica che Prometheus sia in ascolto sulla porta HTTP.
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/9090'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 15s
    restart: unless-stopped

  # =========================
  # Grafana
  # =========================
  # Visualizzazione delle metriche raccolte da Prometheus.
  grafana:
    build:
      context: ./grafana
    container_name: sanitech-grafana
    depends_on:
      - prometheus
    environment:
      GF_SECURITY_ADMIN_USER: ${GF_SECURITY_ADMIN_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${GF_SECURITY_ADMIN_PASSWORD}
    ports:
      # Espone l'interfaccia web sull'host.
      - "3000:3000"
    volumes:
      # Persistenza dati (dashboard, utenti, datasource).
      - grafana-data:/var/lib/grafana
    healthcheck:
      # Verifica che Grafana sia in ascolto sulla porta HTTP.
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/3000'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 20s
    restart: unless-stopped

  # =========================
  # Postgres (one per service)
  # =========================
  pg-directory:
    image: postgres:16
    container_name: sanitech-pg-directory
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${DIRECTORY_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-directory-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${DIRECTORY_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  pg-scheduling:
    image: postgres:16
    container_name: sanitech-pg-scheduling
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${SCHEDULING_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-scheduling-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${SCHEDULING_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  pg-admissions:
    image: postgres:16
    container_name: sanitech-pg-admissions
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${ADMISSIONS_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-admissions-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${ADMISSIONS_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  pg-consents:
    image: postgres:16
    container_name: sanitech-pg-consents
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${CONSENTS_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-consents-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${CONSENTS_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  pg-docs:
    image: postgres:16
    container_name: sanitech-pg-docs
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${DOCS_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-docs-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${DOCS_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  pg-gateway:
    image: postgres:16
    container_name: sanitech-pg-gateway
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${GATEWAY_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-gateway-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${GATEWAY_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  pg-notifications:
    image: postgres:16
    container_name: sanitech-pg-notifications
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${NOTIFICATIONS_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-notifications-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${NOTIFICATIONS_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  pg-audit:
    image: postgres:16
    container_name: sanitech-pg-audit
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${AUDIT_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-audit-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${AUDIT_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  pg-televisit:
    image: postgres:16
    container_name: sanitech-pg-televisit
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${TELEVISIT_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-televisit-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${TELEVISIT_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  pg-payments:
    image: postgres:16
    container_name: sanitech-pg-payments
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${PAYMENTS_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-payments-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${PAYMENTS_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  pg-prescribing:
    image: postgres:16
    container_name: sanitech-pg-prescribing
    environment:
      # Mapping tecnico richiesto dall'immagine Postgres.
      POSTGRES_DB: ${PRESCRIBING_DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      # Persistenza dei dati tra restart dei container
      - pg-prescribing-data:/var/lib/postgresql/data
    healthcheck:
      # Verifica che il database sia pronto ad accettare connessioni
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${PRESCRIBING_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  # =========================
  # Microservices (built from ../sanitech-svc/*)
  # =========================
  svc-gateway:
    build:
      context: ../sanitech-svc/svc-gateway
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-gateway:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-gateway
    depends_on:
      pg-gateway:
        condition: service_healthy
      kafka:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${GATEWAY_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      SERVER_PORT: ${GATEWAY_SERVER_PORT}
      DATABASE_NAME: ${GATEWAY_DATABASE_NAME}
      DIRECTORY_URL: ${GATEWAY_DIRECTORY_URL}
      SCHEDULING_URL: ${GATEWAY_SCHEDULING_URL}
      ADMISSIONS_URL: ${GATEWAY_ADMISSIONS_URL}
      CONSENTS_URL: ${GATEWAY_CONSENTS_URL}
      DOCS_URL: ${GATEWAY_DOCS_URL}
      NOTIFICATIONS_URL: ${GATEWAY_NOTIFICATIONS_URL}
      AUDIT_URL: ${GATEWAY_AUDIT_URL}
      TELEVISIT_URL: ${GATEWAY_TELEVISIT_URL}
      PAYMENTS_URL: ${GATEWAY_PAYMENTS_URL}
      PRESCRIBING_URL: ${GATEWAY_PRESCRIBING_URL}
      OPENAPI_DIRECTORY_URL: ${GATEWAY_OPENAPI_DIRECTORY_URL}
      OPENAPI_SCHEDULING_URL: ${GATEWAY_OPENAPI_SCHEDULING_URL}
      OPENAPI_ADMISSIONS_URL: ${GATEWAY_OPENAPI_ADMISSIONS_URL}
      OPENAPI_CONSENTS_URL: ${GATEWAY_OPENAPI_CONSENTS_URL}
      OPENAPI_DOCS_URL: ${GATEWAY_OPENAPI_DOCS_URL}
      OPENAPI_NOTIFICATIONS_URL: ${GATEWAY_OPENAPI_NOTIFICATIONS_URL}
      OPENAPI_AUDIT_URL: ${GATEWAY_OPENAPI_AUDIT_URL}
      OPENAPI_TELEVISIT_URL: ${GATEWAY_OPENAPI_TELEVISIT_URL}
      OPENAPI_PAYMENTS_URL: ${GATEWAY_OPENAPI_PAYMENTS_URL}
      OPENAPI_PRESCRIBING_URL: ${GATEWAY_OPENAPI_PRESCRIBING_URL}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8080'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

  # Microservizio Java (Spring Boot). Il JAR viene compilato esternamente e poi inserito nell'immagine Docker.
  svc-directory:
    build:
      context: ../sanitech-svc/svc-directory
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-directory:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-directory
    depends_on:
      pg-directory:
        condition: service_healthy
      kafka:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      # Espone API REST sull'host.
      - "8082:8082"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${DIRECTORY_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      OUTBOX_PUBLISHER_ENABLED: ${OUTBOX_PUBLISHER_ENABLED}
      OUTBOX_PUBLISHER_DELAY_MS: ${OUTBOX_PUBLISHER_DELAY_MS}
      OUTBOX_TOPIC: ${DIRECTORY_OUTBOX_TOPIC}
      SERVER_PORT: ${DIRECTORY_SERVER_PORT}
      DATABASE_NAME: ${DIRECTORY_DATABASE_NAME}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8082'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

  svc-scheduling:
    build:
      context: ../sanitech-svc/svc-scheduling
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-scheduling:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-scheduling
    depends_on:
      pg-scheduling:
        condition: service_healthy
      kafka:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${SCHEDULING_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      OUTBOX_PUBLISHER_ENABLED: ${OUTBOX_PUBLISHER_ENABLED}
      OUTBOX_PUBLISHER_DELAY_MS: ${OUTBOX_PUBLISHER_DELAY_MS}
      OUTBOX_TOPIC: ${SCHEDULING_OUTBOX_TOPIC}
      SERVER_PORT: ${SCHEDULING_SERVER_PORT}
      DATABASE_NAME: ${SCHEDULING_DATABASE_NAME}
      DIRECTORY_URL: ${SCHEDULING_DIRECTORY_URL}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8083'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

  svc-admissions:
    build:
      context: ../sanitech-svc/svc-admissions
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-admissions:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-admissions
    depends_on:
      pg-admissions:
        condition: service_healthy
      kafka:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8084:8084"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${ADMISSIONS_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      OUTBOX_PUBLISHER_ENABLED: ${OUTBOX_PUBLISHER_ENABLED}
      OUTBOX_PUBLISHER_DELAY_MS: ${OUTBOX_PUBLISHER_DELAY_MS}
      OUTBOX_TOPIC: ${ADMISSIONS_OUTBOX_TOPIC}
      SERVER_PORT: ${ADMISSIONS_SERVER_PORT}
      DATABASE_NAME: ${ADMISSIONS_DATABASE_NAME}
      DIRECTORY_URL: ${ADMISSIONS_DIRECTORY_URL}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8084'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

  svc-consents:
    build:
      context: ../sanitech-svc/svc-consents
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-consents:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-consents
    depends_on:
      pg-consents:
        condition: service_healthy
      kafka:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8085:8085"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${CONSENTS_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      OUTBOX_PUBLISHER_ENABLED: ${OUTBOX_PUBLISHER_ENABLED}
      OUTBOX_PUBLISHER_DELAY_MS: ${OUTBOX_PUBLISHER_DELAY_MS}
      OUTBOX_TOPIC: ${CONSENTS_OUTBOX_TOPIC}
      SERVER_PORT: ${CONSENTS_SERVER_PORT}
      DATABASE_NAME: ${CONSENTS_DATABASE_NAME}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8085'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

  svc-docs:
    build:
      context: ../sanitech-svc/svc-docs
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-docs:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-docs
    depends_on:
      pg-docs:
        condition: service_healthy
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8086:8086"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${DOCS_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      OUTBOX_PUBLISHER_ENABLED: ${OUTBOX_PUBLISHER_ENABLED}
      OUTBOX_PUBLISHER_DELAY_MS: ${OUTBOX_PUBLISHER_DELAY_MS}
      OUTBOX_TOPIC: ${DOCS_OUTBOX_TOPIC}
      SERVER_PORT: ${DOCS_SERVER_PORT}
      DATABASE_NAME: ${DOCS_DATABASE_NAME}
      CONSENTS_BASE_URL: ${DOCS_CONSENTS_BASE_URL}
      S3_ENDPOINT: ${DOCS_S3_ENDPOINT}
      S3_REGION: ${DOCS_S3_REGION}
      S3_ACCESS_KEY: ${DOCS_S3_ACCESS_KEY}
      S3_SECRET_KEY: ${DOCS_S3_SECRET_KEY}
      S3_BUCKET: ${DOCS_S3_BUCKET}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8086'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

  svc-notifications:
    build:
      context: ../sanitech-svc/svc-notifications
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-notifications:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-notifications
    depends_on:
      pg-notifications:
        condition: service_healthy
      kafka:
        condition: service_healthy
      mailhog:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8087:8087"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${NOTIFICATIONS_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      OUTBOX_PUBLISHER_ENABLED: ${OUTBOX_PUBLISHER_ENABLED}
      OUTBOX_PUBLISHER_DELAY_MS: ${OUTBOX_PUBLISHER_DELAY_MS}
      OUTBOX_TOPIC: ${NOTIFICATIONS_OUTBOX_TOPIC}
      SERVER_PORT: ${NOTIFICATIONS_SERVER_PORT}
      DATABASE_NAME: ${NOTIFICATIONS_DATABASE_NAME}
      MAIL_HOST: ${NOTIFICATIONS_MAIL_HOST}
      MAIL_PORT: ${NOTIFICATIONS_MAIL_PORT}
      MAIL_FROM: ${NOTIFICATIONS_MAIL_FROM}
      NOTIFICATIONS_DISPATCHER_DELAY_MS: ${NOTIFICATIONS_DISPATCHER_DELAY_MS}
      NOTIFICATIONS_DISPATCHER_BATCH_SIZE: ${NOTIFICATIONS_DISPATCHER_BATCH_SIZE}
      MAILPIT_UI_AUTH: ${MAILPIT_UI_AUTH}
      MAILHOG_URL: ${NOTIFICATIONS_MAILHOG_URL}
      SMTP_HOST: ${NOTIFICATIONS_MAIL_HOST}
      SMTP_PORT: ${NOTIFICATIONS_MAIL_PORT}
      DIRECTORY_URL: ${NOTIFICATIONS_DIRECTORY_URL}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8087'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

  svc-audit:
    build:
      context: ../sanitech-svc/svc-audit
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-audit:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-audit
    depends_on:
      pg-audit:
        condition: service_healthy
      kafka:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8088:8088"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${AUDIT_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      OUTBOX_PUBLISHER_ENABLED: ${OUTBOX_PUBLISHER_ENABLED}
      OUTBOX_PUBLISHER_DELAY_MS: ${OUTBOX_PUBLISHER_DELAY_MS}
      OUTBOX_TOPIC: ${AUDIT_OUTBOX_TOPIC}
      SERVER_PORT: ${AUDIT_SERVER_PORT}
      DATABASE_NAME: ${AUDIT_DATABASE_NAME}
      AUDIT_INGESTION_TOPICS: ${AUDIT_INGESTION_TOPICS}
      KAFKA_CONSUMER_GROUP: ${AUDIT_KAFKA_CONSUMER_GROUP}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8088'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

  svc-televisit:
    build:
      context: ../sanitech-svc/svc-televisit
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-televisit:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-televisit
    depends_on:
      pg-televisit:
        condition: service_healthy
      kafka:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      livekit:
        condition: service_started
    ports:
      - "8089:8089"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${TELEVISIT_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      OUTBOX_PUBLISHER_ENABLED: ${OUTBOX_PUBLISHER_ENABLED}
      OUTBOX_PUBLISHER_DELAY_MS: ${OUTBOX_PUBLISHER_DELAY_MS}
      OUTBOX_TOPIC: ${TELEVISIT_OUTBOX_TOPIC}
      SERVER_PORT: ${TELEVISIT_SERVER_PORT}
      DATABASE_NAME: ${TELEVISIT_DATABASE_NAME}
      LIVEKIT_URL: ${LIVEKIT_URL}
      LIVEKIT_WS_URL: ${LIVEKIT_WS_URL}
      LIVEKIT_API_KEY: ${LIVEKIT_API_KEY}
      LIVEKIT_API_SECRET: ${LIVEKIT_API_SECRET}
      LIVEKIT_CONSOLE_URL: ${LIVEKIT_CONSOLE_URL}
      LIVEKIT_TOKEN_TTL_SECONDS: ${LIVEKIT_TOKEN_TTL_SECONDS}
      DIRECTORY_URL: ${TELEVISIT_DIRECTORY_URL}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8089'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

  svc-payments:
    build:
      context: ../sanitech-svc/svc-payments
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-payments:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-payments
    depends_on:
      pg-payments:
        condition: service_healthy
      kafka:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8090:8090"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${PAYMENTS_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      OUTBOX_PUBLISHER_ENABLED: ${OUTBOX_PUBLISHER_ENABLED}
      OUTBOX_PUBLISHER_DELAY_MS: ${OUTBOX_PUBLISHER_DELAY_MS}
      OUTBOX_TOPIC: ${PAYMENTS_OUTBOX_TOPIC}
      SERVER_PORT: ${PAYMENTS_SERVER_PORT}
      DATABASE_NAME: ${PAYMENTS_DATABASE_NAME}
      SANITECH_PAYMENTS_WEBHOOK_SECRET: ${SANITECH_PAYMENTS_WEBHOOK_SECRET}
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8090'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

  svc-prescribing:
    build:
      context: ../sanitech-svc/svc-prescribing
      dockerfile: src/main/docker/Dockerfile
      args:
        JAR_FILE: target/*.jar
    image: sanitech/svc-prescribing:${SPRING_PROFILES_ACTIVE:-local}
    container_name: sanitech-svc-prescribing
    depends_on:
      pg-prescribing:
        condition: service_healthy
      kafka:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8091:8091"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-local}
      DATABASE_HOST: ${PRESCRIBING_DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT}
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_PRODUCER_ACKS: ${KAFKA_PRODUCER_ACKS}
      KAFKA_PRODUCER_RETRIES: ${KAFKA_PRODUCER_RETRIES}
      KAFKA_PRODUCER_LINGER_MS: ${KAFKA_PRODUCER_LINGER_MS}
      OAUTH2_SCHEME: ${OAUTH2_SCHEME}
      OAUTH2_HOST: ${OAUTH2_HOST}
      OAUTH2_PORT: ${OAUTH2_PORT}
      OAUTH2_REALM: ${OAUTH2_REALM}
      OAUTH2_ISSUER_URI: ${OAUTH2_ISSUER_URI}
      OUTBOX_PUBLISHER_ENABLED: ${OUTBOX_PUBLISHER_ENABLED}
      OUTBOX_PUBLISHER_DELAY_MS: ${OUTBOX_PUBLISHER_DELAY_MS}
      OUTBOX_TOPIC: ${PRESCRIBING_OUTBOX_TOPIC}
      SERVER_PORT: ${PRESCRIBING_SERVER_PORT}
      DATABASE_NAME: ${PRESCRIBING_DATABASE_NAME}
      CONSENTS_BASE_URL: ${PRESCRIBING_CONSENTS_BASE_URL}
    healthcheck:
      # Verifica che il microservizio sia in ascolto sulla porta applicativa
      test: ["CMD-SHELL", "sh -c 'exec 3<>/dev/tcp/127.0.0.1/8091'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 25s
    restart: unless-stopped

volumes:
  grafana-data:
  kafka-data:
  minio-data:
  pg-admissions-data:
  pg-audit-data:
  pg-consents-data:
  pg-directory-data:
  pg-docs-data:
  pg-gateway-data:
  pg-notifications-data:
  pg-payments-data:
  pg-prescribing-data:
  pg-scheduling-data:
  pg-televisit-data:
  prometheus-data:
